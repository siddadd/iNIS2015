%Introduction

Many chip-makers are now earmarking a significant amount of research effort for 
vision-based processors. Texas Instruments offers a heterogenous multi-core DSP for real-time vision applications using their Keystone architecture. 
Recently Freescale Semiconductor unveiled a vision system-on-chip - S32V - for accident-free-cars. Camera-friendly wearable devices like Google Glass are 
demanding better power efficiencies, improved performance and more powerful capabilities from the underlying technologies. 

In the context of real-time vision applications, single-class object detection is a highly computationally intensive task.  
To robustly detect an object
in an image that may appear at arbitrary position and scale involves (1) extracting optimized features that aptly describe the object and (2) 
searching the image in a sliding window fashion for the presence of particular configurations of the features that are indicative of the object's presence. 
This exhaustive search is compounded by objects that exhibit high appearance variability in shape, color and size. 
But, for visual-assist systems, the ability to perform such a task is imperative. For example, in a visual driving
assist system, an approaching vehicle or a passing pedestrian needs to be detected
with minimal latency, minimum false positives, and maximum accuracy. On the other hand, a wearable visual prosthesis device needs to augment the visual cognition of the user 
in diverse and vastly unconstrained environments for extended periods of time.

In this paper, we focus on xyz.
To augment the next generation of wearables, we lay emphasis on abc.
The main contributions of this paper are:
%\vspace{-0.1in}
\begin{itemize}
\item We survey the state-of-the-art. 
\item We exploit reliability. 
\end{itemize}

The rest of this paper is organized as follows:
In Section~\ref{sec:related}, we provide an overview of vision-based architectures and the corresponding state-of-the-art.
Section~\ref{sec:reliability} describes a robust object recogntion pipeline.
Finally, we conclude with Section~\ref{sec:conclusion}.


